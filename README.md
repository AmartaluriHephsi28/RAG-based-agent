RAG-Based Document Q&A Agent using Azure OpenAI, AstraDB, and GPT-3.5 Turbo
This project is a Retrieval-Augmented Generation (RAG) application that allows users to interact with documents in natural language using the power of Azure OpenAI and vector search.

**Tech Stack**
Azure OpenAI GPT-3.5 Turbo: Powers the conversational agent for natural and context-aware responses.

Text Embedding (text-embedding-ada-002): Used to convert document chunks into vector representations.

AstraDB (by DataStax): A serverless, scalable vector database used for efficient storage and retrieval of embeddings.

**Features**
Upload and parse documents (e.g., PDFs, text files)

Generate and store vector embeddings

Perform semantic search using AstraDB

Provide accurate, contextual answers to user queries using GPT-3.5 Turbo

Fast and scalable architecture suitable for real-time document Q&A

**Use Cases**
Document search assistants

Enterprise knowledge base bots

Research paper summarization

Legal or medical document analysis
